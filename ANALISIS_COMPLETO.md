# ðŸ“š DOCUMENTACIÃ“N COMPLETA - ANÃLISIS AVANZADO DE DESERCIÃ“N

## ðŸŽ¯ RESUMEN EJECUTIVO

Este proyecto implementa un anÃ¡lisis **completo y multi-enfoque** para predicciÃ³n de deserciÃ³n estudiantil:

1. âœ… **Aprendizaje Supervisado** - Modelos de clasificaciÃ³n tradicionales
2. âœ… **Aprendizaje No Supervisado** - Clustering y segmentaciÃ³n de estudiantes
3. âœ… **Aprendizaje Profundo** - Redes neuronales con TensorFlow/Keras

---

## ðŸ“ ESTRUCTURA COMPLETA DEL PROYECTO

```
UPC/
â”œâ”€â”€ ðŸ”µ ANÃLISIS SUPERVISADO
â”‚   â”œâ”€â”€ TrabajoFinal.py                # Pipeline completo (RF, LR, SVM)
â”‚   â”œâ”€â”€ generar_graficos.py            # Visualizaciones rÃ¡pidas
â”‚   â””â”€â”€ generar_benchmark.py           # ComparaciÃ³n de algoritmos
â”‚
â”œâ”€â”€ ðŸŸ¢ ANÃLISIS NO SUPERVISADO
â”‚   â””â”€â”€ analisis_clustering.py         # K-Means, DBSCAN, PCA
â”‚
â”œâ”€â”€ ðŸŸ  APRENDIZAJE PROFUNDO
â”‚   â””â”€â”€ modelo_deep_learning.py        # Redes neuronales
â”‚
â”œâ”€â”€ ðŸ“Š ANÃLISIS DE DATOS
â”‚   â”œâ”€â”€ resumen_dataset.py             # EDA inicial
â”‚   â””â”€â”€ resumen_final_dataset.py       # Dashboard completo
â”‚
â”œâ”€â”€ ðŸŽ¨ PRESENTACIÃ“N
â”‚   â”œâ”€â”€ generar_slides.py              # Generador de slides
â”‚   â”œâ”€â”€ GUIA_EXPOSICION.md            # GuÃ­a para presentar
â”‚   â””â”€â”€ GUION_PRESENTACION.md         # Script completo
â”‚
â”œâ”€â”€ ðŸ“„ DOCUMENTACIÃ“N
â”‚   â”œâ”€â”€ README.md                      # Este archivo
â”‚   â”œâ”€â”€ INFORME_COMPLETO.md           # AnÃ¡lisis tÃ©cnico detallado
â”‚   â”œâ”€â”€ RESUMEN_EJECUTIVO.md          # Para stakeholders
â”‚   â””â”€â”€ .github/copilot-instructions.md # GuÃ­a para AI agents
â”‚
â””â”€â”€ ðŸ—‚ï¸ artifacts/                      # Todos los resultados
    â”œâ”€â”€ Modelos ML (.pkl, .h5)
    â”œâ”€â”€ Benchmarks (.csv)
    â”œâ”€â”€ Visualizaciones (.png)
    â””â”€â”€ AnÃ¡lisis (.csv)
```

---

## ðŸš€ GUÃA DE USO RÃPIDA

### **Requisitos Previos**

```bash
# Python 3.8+
pip install numpy pandas matplotlib seaborn scikit-learn imbalanced-learn
pip install tensorflow  # Para Deep Learning
pip install shap        # Para interpretabilidad (opcional)
```

### **EjecuciÃ³n de Scripts**

#### 1ï¸âƒ£ AnÃ¡lisis Supervisado (Modelos Tradicionales)

```bash
# AnÃ¡lisis completo con 3 algoritmos
python TrabajoFinal.py

# Solo grÃ¡ficos (rÃ¡pido)
python generar_graficos.py

# Benchmark detallado
python generar_benchmark.py
```

**Salidas:**
- `artifacts/modelo_desercion.pkl` - Mejor modelo entrenado
- `artifacts/benchmark_modelos.csv` - ComparaciÃ³n de algoritmos
- `artifacts/curva_precision_recall.png` - Curvas de rendimiento
- `artifacts/matriz_confusion_umbral_optimo.png` - Matriz optimizada

#### 2ï¸âƒ£ AnÃ¡lisis No Supervisado (Clustering)

```bash
python analisis_clustering.py
```

**Salidas:**
- `artifacts/clustering_perfiles.csv` - Perfiles de estudiantes identificados
- `artifacts/clustering_visualizacion_2d.png` - Clusters en 2D (PCA)
- `artifacts/clustering_visualizacion_3d.png` - Clusters en 3D (PCA)
- `artifacts/pca_varianza_explicada.png` - AnÃ¡lisis de componentes principales

#### 3ï¸âƒ£ Aprendizaje Profundo (Deep Learning)

```bash
python modelo_deep_learning.py
```

**Salidas:**
- `artifacts/modelo_deep_learning.h5` - Red neuronal entrenada
- `artifacts/deep_learning_benchmark_comparison.csv` - ComparaciÃ³n DL vs ML
- `artifacts/deep_learning_roc_pr_curves.png` - Curvas de evaluaciÃ³n
- `artifacts/deep_learning_comparison_chart.png` - GrÃ¡fico comparativo

#### 4ï¸âƒ£ AnÃ¡lisis Exploratorio de Datos

```bash
python resumen_dataset.py          # AnÃ¡lisis bÃ¡sico
python resumen_final_dataset.py    # Dashboard completo
```

#### 5ï¸âƒ£ Generar PresentaciÃ³n

```bash
python generar_slides.py
```

---

## ðŸ“Š RESULTADOS Y MÃ‰TRICAS

### **ðŸ”µ Aprendizaje Supervisado**

| Algoritmo | AUC | Precision | Recall | F1-Score | Mejor para |
|-----------|-----|-----------|--------|----------|-----------|
| **Random Forest** | **0.932** | **0.845** | **0.785** | **0.814** | Balance general |
| Logistic Regression | 0.926 | 0.779 | 0.831 | 0.804 | Interpretabilidad |
| SVM | 0.922 | 0.801 | 0.792 | 0.796 | Fronteras complejas |

**ConclusiÃ³n:** Random Forest es el ganador con 93.2% AUC

### **ðŸŸ¢ Aprendizaje No Supervisado**

**Clustering K-Means:**
- **K Ã³ptimo:** 3-4 clusters (depende de mÃ©trica)
- **Silhouette Score:** ~0.25-0.35
- **Perfiles identificados:**
  - ðŸ”´ Cluster Alto Riesgo (>50% deserciÃ³n)
  - ðŸŸ  Cluster Riesgo Moderado (30-50% deserciÃ³n)
  - ðŸŸ¢ Cluster Bajo Riesgo (<30% deserciÃ³n)

**DBSCAN:**
- **Outliers detectados:** ~5-10% de estudiantes
- **AplicaciÃ³n:** Identificar casos atÃ­picos que requieren atenciÃ³n especial

**PCA (ReducciÃ³n Dimensional):**
- **2 componentes:** ~40-45% varianza explicada
- **3 componentes:** ~50-55% varianza explicada
- **95% varianza:** Requiere ~10-12 componentes

### **ðŸŸ  Aprendizaje Profundo**

**Arquitectura de Red Neuronal:**
```
Input Layer (N features)
    â†“
Hidden Layer 1 (128 neurons, ReLU) + BatchNorm + Dropout(0.4)
    â†“
Hidden Layer 2 (64 neurons, ReLU) + BatchNorm + Dropout(0.3)
    â†“
Hidden Layer 3 (32 neurons, ReLU) + Dropout(0.2)
    â†“
Output Layer (1 neuron, Sigmoid)
```

**Resultados esperados:**
- **AUC:** ~0.92-0.94 (comparable o superior a RF)
- **Training time:** 2-5 minutos (100 epochs con early stopping)
- **Ventaja:** Captura relaciones no lineales complejas
- **Desventaja:** Menos interpretable, requiere mÃ¡s datos

---

## ðŸ” ANÃLISIS DETALLADO POR ENFOQUE

### **1. Aprendizaje Supervisado (ClasificaciÃ³n)**

**Objetivo:** Predecir si un estudiante va a desertar (SÃ­/No)

**Proceso:**
1. Preprocesamiento: StandardScaler + OneHotEncoder
2. Balanceo: SMOTE para equilibrar clases
3. Entrenamiento: 3 algoritmos con validaciÃ³n cruzada
4. OptimizaciÃ³n: GridSearchCV para hiperparÃ¡metros
5. Ajuste de umbral: Maximizar recall â‰¥ 85%

**Variables mÃ¡s importantes:**
1. Unidades curriculares 2do semestre (aprobadas/notas)
2. Unidades curriculares 1er semestre (aprobadas/notas)
3. Edad al momento de inscripciÃ³n
4. Estado de pagos
5. Estado civil

### **2. Aprendizaje No Supervisado (Clustering)**

**Objetivo:** Identificar perfiles naturales de estudiantes sin etiquetas previas

**Proceso:**
1. SelecciÃ³n de features numÃ©ricas relevantes
2. NormalizaciÃ³n con StandardScaler
3. PCA para reducciÃ³n dimensional y visualizaciÃ³n
4. K-Means para segmentaciÃ³n
5. DBSCAN para detecciÃ³n de outliers
6. AnÃ¡lisis de perfiles por cluster

**Aplicaciones prÃ¡cticas:**
- Identificar grupos de riesgo sin supervisiÃ³n
- Detectar patrones no obvios en los datos
- Segmentar estudiantes para intervenciones personalizadas
- Encontrar casos atÃ­picos que requieren atenciÃ³n especial

### **3. Aprendizaje Profundo (Redes Neuronales)**

**Objetivo:** Explorar si arquitecturas complejas mejoran la predicciÃ³n

**Proceso:**
1. Preprocesamiento similar a supervisado
2. DiseÃ±o de arquitectura: 3-4 capas ocultas
3. RegularizaciÃ³n: Dropout, BatchNormalization
4. OptimizaciÃ³n: Adam optimizer con learning rate decay
5. Early stopping para evitar overfitting
6. ComparaciÃ³n con modelos tradicionales

**Ventajas del Deep Learning:**
- Aprende representaciones automÃ¡ticas
- Captura interacciones complejas entre variables
- Escalable a grandes datasets
- Estado del arte en muchos dominios

**CuÃ¡ndo usar cada enfoque:**
- **Supervisado tradicional:** Dataset pequeÃ±o-mediano, interpretabilidad importante
- **Deep Learning:** Dataset grande, relaciones muy complejas
- **No supervisado:** ExploraciÃ³n inicial, sin etiquetas, descubrir patrones

---

## ðŸ“ˆ INSIGHTS Y RECOMENDACIONES

### **Hallazgos Principales**

1. **ðŸ“š Rendimiento acadÃ©mico es el factor #1**
   - CorrelaciÃ³n -0.57 con deserciÃ³n
   - Primeros 2 semestres son crÃ­ticos

2. **ðŸ‘¤ Edad importa**
   - Estudiantes >25 aÃ±os tienen 40% mÃ¡s riesgo
   - Requieren apoyo diferenciado

3. **ðŸ’° Factores econÃ³micos son secundarios pero relevantes**
   - Pagos atrasados: +23% riesgo
   - Becarios: -25% riesgo

4. **ðŸ• Turno nocturno aumenta riesgo**
   - CorrelaciÃ³n +0.21 con deserciÃ³n
   - Probablemente por trabajo/familia

### **Recomendaciones de ImplementaciÃ³n**

#### **Fase 1: Sistema de Alerta Temprana (0-3 meses)**
```python
# PseudocÃ³digo del sistema
for estudiante in matriculados:
    riesgo_score = modelo_rf.predict_proba(estudiante)[1]
    
    if riesgo_score > 0.7:
        enviar_alerta("CRÃTICO", consejero, estudiante)
    elif riesgo_score > 0.5:
        enviar_alerta("MODERADO", consejero, estudiante)
```

#### **Fase 2: SegmentaciÃ³n para Intervenciones (3-6 meses)**
```python
# Usar clustering para personalizar
cluster_estudiante = modelo_kmeans.predict(estudiante)

if cluster_estudiante == ALTO_RIESGO:
    intervenciones = ["tutorÃ­a_intensiva", "apoyo_psicopedagÃ³gico"]
elif cluster_estudiante == RIESGO_MODERADO:
    intervenciones = ["tutorÃ­a_grupal", "mentoring"]
```

#### **Fase 3: Refinamiento con Deep Learning (6-12 meses)**
```python
# Reentrenar con mÃ¡s datos
modelo_dl.fit(nuevos_datos, nuevas_etiquetas)

# Comparar con modelo actual
if performance_dl > performance_rf:
    modelo_produccion = modelo_dl
```

---

## ðŸŽ“ ASPECTOS TÃ‰CNICOS AVANZADOS

### **Manejo de Datos Desbalanceados**

**Problema:** Solo 32.1% de estudiantes desertan

**Soluciones implementadas:**
1. **SMOTE:** Genera ejemplos sintÃ©ticos de la clase minoritaria
2. **Estratified Sampling:** Mantiene proporciones en train/test
3. **MÃ©tricas apropiadas:** AUC, F1, Precision-Recall (no solo Accuracy)
4. **Ajuste de umbral:** Optimizar segÃºn objetivos de negocio

### **ValidaciÃ³n y GeneralizaciÃ³n**

**TÃ©cnicas usadas:**
1. **Train/Test Split:** 80/20 con stratification
2. **Cross-Validation:** 5-fold estratificada
3. **GridSearchCV:** Para hiperparÃ¡metros
4. **Holdout Test:** Nunca usado en entrenamiento

### **Interpretabilidad**

**Para stakeholders no tÃ©cnicos:**
- Feature importance (Random Forest)
- SHAP values (explicaciones individuales)
- Perfiles de clusters (segmentaciÃ³n entendible)
- Visualizaciones claras (curvas, matrices)

---

## ðŸ’» COMANDOS ÃšTILES

### **InstalaciÃ³n de Dependencias**

```bash
# Instalar todo de una vez
pip install -r requirements.txt

# O manualmente:
pip install numpy pandas matplotlib seaborn
pip install scikit-learn imbalanced-learn
pip install tensorflow  # Para deep learning
pip install shap        # Para interpretabilidad
```

### **Ejecutar Todos los AnÃ¡lisis**

```bash
# Script bash (Linux/Mac)
#!/bin/bash
python resumen_dataset.py
python TrabajoFinal.py
python analisis_clustering.py
python modelo_deep_learning.py
python generar_slides.py
```

```powershell
# PowerShell (Windows)
python resumen_dataset.py
python TrabajoFinal.py
python analisis_clustering.py
python modelo_deep_learning.py
python generar_slides.py
```

### **Cargar Modelos Guardados**

```python
# Cargar Random Forest
import joblib
modelo_rf = joblib.load("artifacts/modelo_desercion.pkl")

# Cargar Deep Learning
from tensorflow import keras
modelo_dl = keras.models.load_model("artifacts/modelo_deep_learning.h5")

# Hacer predicciones
probabilidad_desercion = modelo_rf.predict_proba(nuevo_estudiante)
```

---

## ðŸ“š REFERENCIAS Y RECURSOS

### **DocumentaciÃ³n del Proyecto**
- `INFORME_COMPLETO.md` - AnÃ¡lisis tÃ©cnico detallado
- `RESUMEN_EJECUTIVO.md` - Para tomadores de decisiÃ³n
- `GUIA_EXPOSICION.md` - CÃ³mo presentar el proyecto
- `GUION_PRESENTACION.md` - Script para exposiciÃ³n

### **LibrerÃ­as Utilizadas**
- [Scikit-learn](https://scikit-learn.org/) - ML tradicional
- [TensorFlow/Keras](https://www.tensorflow.org/) - Deep Learning
- [Imbalanced-learn](https://imbalanced-learn.org/) - SMOTE
- [SHAP](https://shap.readthedocs.io/) - Interpretabilidad

### **ArtÃ­culos Relacionados**
- Student Dropout Prediction: A Systematic Review
- Deep Learning for Educational Data Mining
- Clustering Students for Personalized Interventions

---

## ðŸ‘¥ CONTRIBUCIONES Y CONTACTO

**Autor:** [Tu Nombre]  
**Universidad:** Universidad Peruana de Ciencias Aplicadas (UPC)  
**Curso:** Machine Learning / Ciencia de Datos  
**AÃ±o:** 2025

**Para preguntas o colaboraciones:**
- GitHub: [Tu usuario]
- Email: [Tu email]

---

## ðŸ“„ LICENCIA

Este proyecto es de uso acadÃ©mico. Los datos son confidenciales y no deben ser compartidos fuera del contexto educativo.

---

## ðŸŽ¯ PRÃ“XIMOS PASOS

### **Mejoras Futuras**
1. âœ… Implementar modelos de serie temporal (predicciÃ³n por semestre)
2. âœ… Agregar variables de interacciÃ³n social/engagement
3. âœ… API REST para integraciÃ³n con sistemas acadÃ©micos
4. âœ… Dashboard interactivo con Streamlit/Dash
5. âœ… A/B testing de intervenciones basadas en predicciones

### **InvestigaciÃ³n Avanzada**
1. Transfer Learning con datos de otras universidades
2. Modelos ensemble (stacking RF + DL)
3. Reinforcement Learning para optimizar intervenciones
4. Natural Language Processing en comentarios de profesores

---

**ðŸŽ‰ Â¡Proyecto Completo! Ahora tienes anÃ¡lisis supervisado, no supervisado y deep learning implementados.**

**Ãšltima actualizaciÃ³n:** Octubre 2025
