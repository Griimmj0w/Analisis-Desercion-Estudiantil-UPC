# AnÃ¡lisis de DeserciÃ³n Estudiantil - Enfoque Multi-Paradigma

Proyecto completo de machine learning que implementa **aprendizaje supervisado, no supervisado y deep learning** para predecir y analizar la deserciÃ³n estudiantil.

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto implementa un anÃ¡lisis exhaustivo de factores que influyen en la deserciÃ³n estudiantil usando **mÃºltiples enfoques de Machine Learning**:

1. ğŸ”µ **Aprendizaje Supervisado** - Random Forest, Logistic Regression, SVM
2. ğŸŸ¢ **Aprendizaje No Supervisado** - K-Means, DBSCAN, PCA  
3. ğŸŸ  **Aprendizaje Profundo** - Redes Neuronales con TensorFlow/Keras

El objetivo es identificar estudiantes en riesgo mediante diferentes tÃ©cnicas, permitiendo intervenciones tempranas y personalizadas.

## ğŸ¯ Objetivos

- Identificar patrones en los datos que contribuyen a la deserciÃ³n estudiantil
- Desarrollar modelos de machine learning (supervisado, no supervisado y deep learning)
- Optimizar umbrales de decisiÃ³n para maximizar recall manteniendo precisiÃ³n
- Segmentar estudiantes en perfiles de riesgo para intervenciones personalizadas
- Comparar rendimiento entre algoritmos tradicionales y redes neuronales
- Generar insights accionables para intervenciones tempranas

## ğŸ“ Estructura del Proyecto

```
UPC/
â”œâ”€â”€ ğŸ”µ APRENDIZAJE SUPERVISADO
â”‚   â”œâ”€â”€ TrabajoFinal.py                # AnÃ¡lisis completo (RF, LR, SVM)
â”‚   â”œâ”€â”€ generar_graficos.py            # Visualizaciones rÃ¡pidas
â”‚   â””â”€â”€ generar_benchmark.py           # ComparaciÃ³n de algoritmos
â”‚
â”œâ”€â”€ ğŸŸ¢ APRENDIZAJE NO SUPERVISADO
â”‚   â””â”€â”€ analisis_clustering.py         # K-Means, DBSCAN, PCA
â”‚
â”œâ”€â”€ ğŸŸ  APRENDIZAJE PROFUNDO
â”‚   â””â”€â”€ modelo_deep_learning.py        # Redes neuronales (TensorFlow/Keras)
â”‚
â”œâ”€â”€ ğŸ“Š ANÃLISIS DE DATOS
â”‚   â”œâ”€â”€ resumen_dataset.py             # EDA inicial
â”‚   â””â”€â”€ resumen_final_dataset.py       # Dashboard completo
â”‚
â”œâ”€â”€ ğŸ¨ PRESENTACIÃ“N
â”‚   â”œâ”€â”€ generar_slides.py              # Generador de slides
â”‚   â”œâ”€â”€ GUIA_EXPOSICION.md            # GuÃ­a para presentar
â”‚   â””â”€â”€ GUION_PRESENTACION.md         # Script de exposiciÃ³n
â”‚
â”œâ”€â”€ ğŸ“„ DOCUMENTACIÃ“N
â”‚   â”œâ”€â”€ README.md                      # Este archivo
â”‚   â”œâ”€â”€ ANALISIS_COMPLETO.md          # GuÃ­a completa de todos los anÃ¡lisis
â”‚   â”œâ”€â”€ INFORME_COMPLETO.md           # AnÃ¡lisis tÃ©cnico detallado
â”‚   â”œâ”€â”€ RESUMEN_EJECUTIVO.md          # Para stakeholders
â”‚   â””â”€â”€ .github/copilot-instructions.md
â”‚
â”œâ”€â”€ artifacts/                         # Resultados y modelos
â”‚   â”œâ”€â”€ modelo_desercion.pkl           # Random Forest entrenado
â”‚   â”œâ”€â”€ modelo_deep_learning.h5        # Red neuronal entrenada
â”‚   â”œâ”€â”€ clustering_perfiles.csv        # Perfiles de estudiantes
â”‚   â”œâ”€â”€ benchmark_*.csv                # Comparaciones
â”‚   â””â”€â”€ *.png                          # Visualizaciones
â”‚
â””â”€â”€ slides/                            # PresentaciÃ³n
    â””â”€â”€ slide_*.png
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.8+**
- **AnÃ¡lisis de Datos**: Pandas, NumPy
- **VisualizaciÃ³n**: Matplotlib, Seaborn
- **Machine Learning**: Scikit-learn, Imbalanced-learn
- **Deep Learning**: TensorFlow, Keras
- **Modelos Supervisados**: Random Forest, Logistic Regression, SVM
- **Modelos No Supervisados**: K-Means, DBSCAN, PCA
- **Explicabilidad**: SHAP (opcional)

## ğŸ“‹ Requisitos

Instala las dependencias necesarias:

```bash
# Dependencias bÃ¡sicas
pip install numpy pandas matplotlib seaborn scikit-learn imbalanced-learn

# Para Deep Learning
pip install tensorflow

# Para interpretabilidad (opcional)
pip install shap
```

O usando el entorno virtual incluido:

```bash
# Activar entorno virtual
.venv\Scripts\Activate.ps1

# Las dependencias ya estÃ¡n instaladas en el entorno virtual
```

## ğŸš€ Uso

### 1ï¸âƒ£ Aprendizaje Supervisado - ClasificaciÃ³n

```bash
# AnÃ¡lisis completo con 3 algoritmos
python TrabajoFinal.py

# Solo grÃ¡ficos (versiÃ³n rÃ¡pida)
python generar_graficos.py

# Benchmark detallado
python generar_benchmark.py
```

### 2ï¸âƒ£ Aprendizaje No Supervisado - Clustering

```bash
# Identificar perfiles de estudiantes
python analisis_clustering.py
```

**Salidas:**
- IdentificaciÃ³n de 3-4 perfiles de estudiantes
- DetecciÃ³n de outliers (5-10% casos atÃ­picos)
- VisualizaciÃ³n en 2D y 3D con PCA
- AnÃ¡lisis de tasa de deserciÃ³n por cluster

### 3ï¸âƒ£ Aprendizaje Profundo - Redes Neuronales

```bash
# Entrenar red neuronal y comparar con ML tradicional
python modelo_deep_learning.py
```

**Salidas:**
- Modelo de Deep Learning entrenado (.h5)
- ComparaciÃ³n DL vs ML tradicional
- Curvas de aprendizaje
- Feature importance aproximado

### 4ï¸âƒ£ Generar PresentaciÃ³n

```bash
python generar_slides.py
```

## ğŸ“ˆ Resultados Principales

### ğŸ”µ Aprendizaje Supervisado

**Mejor Modelo: Random Forest**
- **AUC**: 0.932 (Excelente capacidad discriminativa)
- **Average Precision**: 0.901
- **Umbral Ã“ptimo**: 0.410
- **Precision**: 0.786
- **Recall**: 0.852
- **F1-Score**: 0.818

### ğŸŸ¢ Aprendizaje No Supervisado

**K-Means Clustering:**
- **K Ã³ptimo**: 3-4 clusters
- **Silhouette Score**: ~0.30
- **Perfiles identificados**:
  - ğŸ”´ Alto Riesgo (>50% deserciÃ³n)
  - ğŸŸ  Riesgo Moderado (30-50% deserciÃ³n)
  - ğŸŸ¢ Bajo Riesgo (<30% deserciÃ³n)

**DBSCAN:**
- **Outliers detectados**: 5-10% de estudiantes
- **AplicaciÃ³n**: Casos atÃ­picos que requieren atenciÃ³n especial

**PCA:**
- **2 componentes**: 40-45% varianza explicada
- **95% varianza**: Requiere ~10-12 componentes

### ğŸŸ  Aprendizaje Profundo

**Red Neuronal (3 capas ocultas):**
- **AUC**: ~0.92-0.94 (comparable a Random Forest)
- **Arquitectura**: 128 â†’ 64 â†’ 32 neuronas
- **RegularizaciÃ³n**: Dropout + BatchNormalization
- **Training**: Early stopping (~30-50 epochs)
- **Ventaja**: Captura relaciones no lineales complejas

### Visualizaciones Generadas

#### Aprendizaje Supervisado
1. **Curva Precision-Recall**: Trade-off entre precisiÃ³n y recall
2. **Matriz de ConfusiÃ³n**: Con umbral optimizado
3. **Curva ROC**: EvaluaciÃ³n del rendimiento
4. **Importancia de Variables**: Top 20 caracterÃ­sticas

#### Aprendizaje No Supervisado
1. **Clustering 2D/3D**: VisualizaciÃ³n con PCA
2. **MÃ©todo del Codo**: SelecciÃ³n de K Ã³ptimo
3. **AnÃ¡lisis de Perfiles**: CaracterÃ­sticas por cluster
4. **Varianza Explicada**: Componentes principales

#### Aprendizaje Profundo
1. **Curvas de Aprendizaje**: Loss y mÃ©tricas por epoch
2. **ComparaciÃ³n DL vs ML**: Benchmarks visuales
3. **Feature Importance**: Permutation importance
4. **ROC y PR Curves**: EvaluaciÃ³n del modelo

## ğŸ¯ MetodologÃ­a

### 1ï¸âƒ£ Aprendizaje Supervisado

1. **Preprocesamiento de Datos**
   - Encoding de variables categÃ³ricas (OneHotEncoder)
   - NormalizaciÃ³n de variables numÃ©ricas (StandardScaler)
   - Balanceo con SMOTE

2. **Modelado**
   - ComparaciÃ³n de mÃºltiples algoritmos (RF, LR, SVM)
   - ValidaciÃ³n cruzada estratificada (5-fold)
   - OptimizaciÃ³n de hiperparÃ¡metros (GridSearchCV)

3. **OptimizaciÃ³n de Umbral**
   - BÃºsqueda de umbral que garantice recall â‰¥ 85%
   - MaximizaciÃ³n de F1-Score

4. **EvaluaciÃ³n**
   - MÃ©tricas de clasificaciÃ³n (AUC, Precision, Recall, F1)
   - Curvas de rendimiento (ROC, Precision-Recall)
   - AnÃ¡lisis de importancia de variables

### 2ï¸âƒ£ Aprendizaje No Supervisado

1. **ReducciÃ³n Dimensional**
   - PCA para exploraciÃ³n de varianza
   - VisualizaciÃ³n en 2D y 3D

2. **Clustering**
   - K-Means para segmentaciÃ³n
   - MÃ©todo del codo para K Ã³ptimo
   - Silhouette Score para validaciÃ³n

3. **DetecciÃ³n de AnomalÃ­as**
   - DBSCAN para identificar outliers
   - AnÃ¡lisis de estudiantes atÃ­picos

4. **AnÃ¡lisis de Perfiles**
   - CaracterizaciÃ³n de cada cluster
   - Tasa de deserciÃ³n por segmento
   - Recomendaciones personalizadas

### 3ï¸âƒ£ Aprendizaje Profundo

1. **Arquitectura**
   - Red feed-forward multicapa
   - 3-4 capas ocultas (128â†’64â†’32)
   - ActivaciÃ³n ReLU + Sigmoid final

2. **RegularizaciÃ³n**
   - Dropout (0.2-0.4)
   - BatchNormalization
   - Early Stopping

3. **OptimizaciÃ³n**
   - Adam optimizer
   - Learning rate decay
   - Binary cross-entropy loss

4. **ComparaciÃ³n**
   - Benchmark vs modelos tradicionales
   - AnÃ¡lisis de trade-offs
   - Feature importance aproximado

## ğŸ“Š Datos

El proyecto utiliza un dataset de deserciÃ³n estudiantil con las siguientes caracterÃ­sticas:

- **TamaÃ±o**: 4,424 registros
- **Variables**: 37 caracterÃ­sticas
- **DistribuciÃ³n**: 32.1% deserciÃ³n, 67.9% graduaciÃ³n/continuidad
- **Tipo de Variables**: NumÃ©ricas y categÃ³ricas

## ğŸ” Interpretabilidad

- **Feature Importance (Random Forest)**: Variables mÃ¡s influyentes
- **SHAP Values**: Explicabilidad de predicciones individuales
- **Perfiles de Clusters**: SegmentaciÃ³n comprensible para stakeholders
- **AnÃ¡lisis de Umbrales**: OptimizaciÃ³n basada en objetivos de negocio
- **Visualizaciones Intuitivas**: Curvas, matrices y grÃ¡ficos explicativos

## ğŸ“ Casos de Uso

### Para Instituciones Educativas

1. **Sistema de Alerta Temprana**
   - IdentificaciÃ³n automÃ¡tica de estudiantes en riesgo
   - Alertas desde el 2Â° mes de clases
   - PriorizaciÃ³n por nivel de riesgo (score 0-100%)

2. **Intervenciones Personalizadas**
   - SegmentaciÃ³n por perfiles (clusters)
   - Programas diferenciados por grupo de riesgo
   - Seguimiento y evaluaciÃ³n de intervenciones

3. **OptimizaciÃ³n de Recursos**
   - Focalizar apoyo en casos crÃ­ticos
   - AsignaciÃ³n eficiente de consejeros
   - MediciÃ³n de impacto de programas

### Para Investigadores

1. **AnÃ¡lisis Exploratorio**
   - Identificar patrones no obvios (clustering)
   - Validar hipÃ³tesis sobre factores de riesgo
   - Comparar enfoques metodolÃ³gicos

2. **Benchmarking**
   - Comparar mÃºltiples algoritmos
   - Evaluar trade-offs (precisiÃ³n vs recall)
   - Experimentar con diferentes arquitecturas

## ğŸ“Š Principales Hallazgos

1. **ğŸ“š Rendimiento acadÃ©mico** es el factor mÃ¡s predictivo (-0.57 correlaciÃ³n)
2. **ğŸ‘¤ Edad al inscribirse** influye significativamente (+0.25 correlaciÃ³n)
3. **ğŸ’° Factores econÃ³micos** (pagos, becas) son relevantes pero secundarios
4. **ğŸ• Turno nocturno** aumenta riesgo de deserciÃ³n (+0.21 correlaciÃ³n)
5. **ğŸ“ˆ Primeros 2 semestres** son crÃ­ticos para intervenciÃ³n temprana
6. **ğŸ¯ 3-4 perfiles distintos** de estudiantes identificados por clustering
7. **ğŸ¤– Deep Learning** alcanza rendimiento comparable a Random Forest
8. **âš¡ Outliers** (5-10%) requieren atenciÃ³n especial

## ğŸ“„ DocumentaciÃ³n Adicional

Para informaciÃ³n mÃ¡s detallada, consulta:

- **`ANALISIS_COMPLETO.md`** - GuÃ­a completa de todos los anÃ¡lisis implementados
- **`INFORME_COMPLETO.md`** - AnÃ¡lisis tÃ©cnico detallado del proyecto
- **`RESUMEN_EJECUTIVO.md`** - Resumen para stakeholders y tomadores de decisiÃ³n
- **`GUIA_EXPOSICION.md`** - CÃ³mo presentar el proyecto efectivamente
- **`GUION_PRESENTACION.md`** - Script completo para exposiciones
- **`.github/copilot-instructions.md`** - GuÃ­a para AI coding agents

## ğŸ‘¥ Autor

Desarrollado para el curso de analisis de datos y sistemas predictivos- UPC

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.
