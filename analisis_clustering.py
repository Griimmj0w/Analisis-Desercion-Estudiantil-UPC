"""
ANÃLISIS NO SUPERVISADO - CLUSTERING DE ESTUDIANTES
====================================================
Script para identificar perfiles de estudiantes usando tÃ©cnicas de clustering.
Implementa K-Means, DBSCAN y PCA para segmentaciÃ³n y visualizaciÃ³n.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import warnings
import os

warnings.filterwarnings("ignore")
os.makedirs("artifacts", exist_ok=True)

print("="*80)
print("     ANÃLISIS NO SUPERVISADO - SEGMENTACIÃ“N DE ESTUDIANTES")
print("="*80)

# ====================================================================
# 1. CARGAR Y PREPARAR DATOS
# ====================================================================
print("\nðŸ“Š 1. Cargando datos...")
df = pd.read_csv(r'C:\\Users\\SISTEMAS\\Documents\\PYTHON\\DATA\\data.csv', sep=';')
df["target_bin"] = (df["Target"] == "Dropout").astype(int)

print(f"   Datos cargados: {df.shape[0]:,} estudiantes Ã— {df.shape[1]} variables")

# Seleccionar solo variables numÃ©ricas mÃ¡s relevantes para clustering
numeric_features = [
    'Age at enrollment',
    'Curricular units 1st sem (credited)',
    'Curricular units 1st sem (enrolled)',
    'Curricular units 1st sem (evaluations)',
    'Curricular units 1st sem (approved)',
    'Curricular units 1st sem (grade)',
    'Curricular units 2nd sem (credited)',
    'Curricular units 2nd sem (enrolled)',
    'Curricular units 2nd sem (evaluations)',
    'Curricular units 2nd sem (approved)',
    'Curricular units 2nd sem (grade)',
    'Admission grade',
    'Previous qualification (grade)',
    'Unemployment rate',
    'Inflation rate',
    'GDP'
]

X = df[numeric_features].copy()
y_true = df["target_bin"].values  # Para validaciÃ³n posterior

print(f"   Variables seleccionadas: {len(numeric_features)}")

# ====================================================================
# 2. PREPROCESAMIENTO - NORMALIZACIÃ“N
# ====================================================================
print("\nðŸ”§ 2. Normalizando datos...")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("   âœ“ Datos normalizados (media=0, std=1)")

# ====================================================================
# 3. REDUCCIÃ“N DE DIMENSIONALIDAD CON PCA
# ====================================================================
print("\nðŸ“‰ 3. Aplicando PCA para reducciÃ³n de dimensionalidad...")

# PCA para anÃ¡lisis de varianza explicada
pca_full = PCA()
pca_full.fit(X_scaled)

# Determinar componentes Ã³ptimos (explicar 95% de varianza)
cumsum_variance = np.cumsum(pca_full.explained_variance_ratio_)
n_components_95 = np.argmax(cumsum_variance >= 0.95) + 1

print(f"   Componentes para 95% varianza: {n_components_95}")
print(f"   Varianza explicada por componente:")
for i, var in enumerate(pca_full.explained_variance_ratio_[:5], 1):
    print(f"      PC{i}: {var*100:.2f}%")

# PCA para visualizaciÃ³n (2D y 3D)
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X_scaled)

pca_3d = PCA(n_components=3)
X_pca_3d = pca_3d.fit_transform(X_scaled)

print(f"   Varianza explicada (2D): {sum(pca_2d.explained_variance_ratio_)*100:.2f}%")
print(f"   Varianza explicada (3D): {sum(pca_3d.explained_variance_ratio_)*100:.2f}%")

# Visualizar varianza explicada acumulada
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(range(1, len(cumsum_variance)+1), cumsum_variance, 'bo-')
plt.axhline(y=0.95, color='r', linestyle='--', label='95% varianza')
plt.xlabel('NÃºmero de Componentes')
plt.ylabel('Varianza Explicada Acumulada')
plt.title('Varianza Explicada por PCA')
plt.grid(alpha=0.3)
plt.legend()

plt.subplot(1, 2, 2)
plt.bar(range(1, 11), pca_full.explained_variance_ratio_[:10], alpha=0.7, color='steelblue')
plt.xlabel('Componente Principal')
plt.ylabel('Varianza Explicada')
plt.title('Varianza por Componente (Top 10)')
plt.grid(alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig("artifacts/pca_varianza_explicada.png", dpi=300, bbox_inches="tight")
print("   âœ“ GrÃ¡fico guardado: artifacts/pca_varianza_explicada.png")
plt.show()

# ====================================================================
# 4. DETERMINAR NÃšMERO Ã“PTIMO DE CLUSTERS (MÃ‰TODO DEL CODO)
# ====================================================================
print("\nðŸ” 4. Determinando nÃºmero Ã³ptimo de clusters (MÃ©todo del Codo)...")

inertias = []
silhouette_scores = []
k_range = range(2, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
    print(f"   K={k}: Inertia={kmeans.inertia_:.0f}, Silhouette={silhouette_scores[-1]:.3f}")

# Visualizar mÃ©todos de selecciÃ³n
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)
axes[0].set_xlabel('NÃºmero de Clusters (K)')
axes[0].set_ylabel('Inertia (Suma de distancias cuadradas)')
axes[0].set_title('MÃ©todo del Codo')
axes[0].grid(alpha=0.3)

axes[1].plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)
axes[1].set_xlabel('NÃºmero de Clusters (K)')
axes[1].set_ylabel('Silhouette Score')
axes[1].set_title('Silhouette Score por K')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig("artifacts/clustering_metodo_codo.png", dpi=300, bbox_inches="tight")
print("   âœ“ GrÃ¡fico guardado: artifacts/clustering_metodo_codo.png")
plt.show()

# Seleccionar K Ã³ptimo (basado en Silhouette)
k_optimo = k_range[np.argmax(silhouette_scores)]
print(f"\n   ðŸ† K Ã³ptimo seleccionado: {k_optimo}")

# ====================================================================
# 5. APLICAR K-MEANS CON K Ã“PTIMO
# ====================================================================
print(f"\nðŸŽ¯ 5. Aplicando K-Means con K={k_optimo}...")

kmeans = KMeans(n_clusters=k_optimo, random_state=42, n_init=10)
clusters_kmeans = kmeans.fit_predict(X_scaled)

# MÃ©tricas de evaluaciÃ³n
silhouette_kmeans = silhouette_score(X_scaled, clusters_kmeans)
davies_bouldin_kmeans = davies_bouldin_score(X_scaled, clusters_kmeans)
calinski_harabasz_kmeans = calinski_harabasz_score(X_scaled, clusters_kmeans)

print(f"   MÃ©tricas K-Means:")
print(f"      Silhouette Score: {silhouette_kmeans:.3f} (Mejor cerca de 1)")
print(f"      Davies-Bouldin Index: {davies_bouldin_kmeans:.3f} (Mejor cerca de 0)")
print(f"      Calinski-Harabasz Index: {calinski_harabasz_kmeans:.0f} (Mayor es mejor)")

# ====================================================================
# 6. APLICAR DBSCAN PARA DETECCIÃ“N DE OUTLIERS
# ====================================================================
print("\nðŸ”Ž 6. Aplicando DBSCAN para detecciÃ³n de outliers...")

# Probar diferentes parÃ¡metros de DBSCAN
eps_values = [0.5, 1.0, 1.5]
min_samples_values = [5, 10, 15]

best_dbscan = None
best_score = -1
best_params = None

print("   Probando combinaciones de parÃ¡metros...")
for eps in eps_values:
    for min_samples in min_samples_values:
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        clusters_dbscan = dbscan.fit_predict(X_scaled)
        
        n_clusters = len(set(clusters_dbscan)) - (1 if -1 in clusters_dbscan else 0)
        n_outliers = list(clusters_dbscan).count(-1)
        
        if n_clusters > 1:  # Solo evaluar si hay mÃ¡s de 1 cluster
            score = silhouette_score(X_scaled[clusters_dbscan != -1], 
                                    clusters_dbscan[clusters_dbscan != -1])
            
            if score > best_score:
                best_score = score
                best_dbscan = clusters_dbscan
                best_params = (eps, min_samples)
                
print(f"\n   Mejor configuraciÃ³n DBSCAN:")
print(f"      eps={best_params[0]}, min_samples={best_params[1]}")
print(f"      Clusters encontrados: {len(set(best_dbscan)) - (1 if -1 in best_dbscan else 0)}")
print(f"      Outliers detectados: {list(best_dbscan).count(-1)} ({list(best_dbscan).count(-1)/len(best_dbscan)*100:.1f}%)")
print(f"      Silhouette Score: {best_score:.3f}")

# ====================================================================
# 7. VISUALIZACIÃ“N DE CLUSTERS EN 2D (PCA)
# ====================================================================
print("\nðŸ“Š 7. Generando visualizaciones...")

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# K-Means en 2D
scatter1 = axes[0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], 
                           c=clusters_kmeans, cmap='viridis', 
                           alpha=0.6, s=20)
axes[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
               c='red', marker='X', s=200, edgecolors='black', linewidths=2,
               label='Centroides')
axes[0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}%)')
axes[0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}%)')
axes[0].set_title(f'K-Means (K={k_optimo}) - Silhouette: {silhouette_kmeans:.3f}')
axes[0].legend()
axes[0].grid(alpha=0.3)
plt.colorbar(scatter1, ax=axes[0], label='Cluster')

# DBSCAN en 2D
scatter2 = axes[1].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], 
                           c=best_dbscan, cmap='plasma', 
                           alpha=0.6, s=20)
axes[1].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}%)')
axes[1].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}%)')
axes[1].set_title(f'DBSCAN - Outliers: {list(best_dbscan).count(-1)}')
axes[1].grid(alpha=0.3)
plt.colorbar(scatter2, ax=axes[1], label='Cluster (-1=Outlier)')

# ComparaciÃ³n con Target Real (DeserciÃ³n)
scatter3 = axes[2].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], 
                           c=y_true, cmap='coolwarm', 
                           alpha=0.6, s=20)
axes[2].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}%)')
axes[2].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}%)')
axes[2].set_title('Etiquetas Reales (0=No DeserciÃ³n, 1=DeserciÃ³n)')
axes[2].grid(alpha=0.3)
plt.colorbar(scatter3, ax=axes[2], label='DeserciÃ³n')

plt.tight_layout()
plt.savefig("artifacts/clustering_visualizacion_2d.png", dpi=300, bbox_inches="tight")
print("   âœ“ GrÃ¡fico guardado: artifacts/clustering_visualizacion_2d.png")
plt.show()

# ====================================================================
# 8. VISUALIZACIÃ“N 3D DE CLUSTERS
# ====================================================================
print("\nðŸ“Š 8. Generando visualizaciÃ³n 3D...")

fig = plt.figure(figsize=(15, 5))

# K-Means 3D
ax1 = fig.add_subplot(131, projection='3d')
scatter1 = ax1.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],
                       c=clusters_kmeans, cmap='viridis', alpha=0.5, s=10)
ax1.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.1f}%)')
ax1.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.1f}%)')
ax1.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.1f}%)')
ax1.set_title(f'K-Means (K={k_optimo})')
plt.colorbar(scatter1, ax=ax1, shrink=0.5)

# DBSCAN 3D
ax2 = fig.add_subplot(132, projection='3d')
scatter2 = ax2.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],
                       c=best_dbscan, cmap='plasma', alpha=0.5, s=10)
ax2.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.1f}%)')
ax2.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.1f}%)')
ax2.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.1f}%)')
ax2.set_title('DBSCAN')
plt.colorbar(scatter2, ax=ax2, shrink=0.5)

# Target Real 3D
ax3 = fig.add_subplot(133, projection='3d')
scatter3 = ax3.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],
                       c=y_true, cmap='coolwarm', alpha=0.5, s=10)
ax3.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.1f}%)')
ax3.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.1f}%)')
ax3.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.1f}%)')
ax3.set_title('DeserciÃ³n Real')
plt.colorbar(scatter3, ax=ax3, shrink=0.5)

plt.tight_layout()
plt.savefig("artifacts/clustering_visualizacion_3d.png", dpi=300, bbox_inches="tight")
print("   âœ“ GrÃ¡fico guardado: artifacts/clustering_visualizacion_3d.png")
plt.show()

# ====================================================================
# 9. ANÃLISIS DE PERFILES POR CLUSTER
# ====================================================================
print("\nðŸ‘¥ 9. AnÃ¡lisis de perfiles por cluster (K-Means)...")

df_analysis = df[numeric_features].copy()
df_analysis['Cluster'] = clusters_kmeans
df_analysis['Desercion'] = y_true

# EstadÃ­sticas por cluster
print("\n   ðŸ“‹ EstadÃ­sticas por Cluster:")
print("   " + "-"*70)

cluster_profiles = []
for cluster_id in range(k_optimo):
    cluster_data = df_analysis[df_analysis['Cluster'] == cluster_id]
    n_estudiantes = len(cluster_data)
    tasa_desercion = cluster_data['Desercion'].mean() * 100
    edad_promedio = cluster_data['Age at enrollment'].mean()
    nota_1sem = cluster_data['Curricular units 1st sem (grade)'].mean()
    nota_2sem = cluster_data['Curricular units 2nd sem (grade)'].mean()
    
    print(f"\n   ðŸ”¹ CLUSTER {cluster_id}:")
    print(f"      Estudiantes: {n_estudiantes} ({n_estudiantes/len(df_analysis)*100:.1f}%)")
    print(f"      Tasa de DeserciÃ³n: {tasa_desercion:.1f}%")
    print(f"      Edad promedio: {edad_promedio:.1f} aÃ±os")
    print(f"      Nota 1er sem: {nota_1sem:.2f}")
    print(f"      Nota 2do sem: {nota_2sem:.2f}")
    
    # Clasificar cluster por nivel de riesgo
    if tasa_desercion > 50:
        riesgo = "ðŸ”´ ALTO RIESGO"
    elif tasa_desercion > 30:
        riesgo = "ðŸŸ  RIESGO MODERADO"
    else:
        riesgo = "ðŸŸ¢ BAJO RIESGO"
    
    print(f"      Perfil: {riesgo}")
    
    cluster_profiles.append({
        'Cluster': cluster_id,
        'N_Estudiantes': n_estudiantes,
        'Porcentaje': f"{n_estudiantes/len(df_analysis)*100:.1f}%",
        'Tasa_Desercion': f"{tasa_desercion:.1f}%",
        'Edad_Promedio': f"{edad_promedio:.1f}",
        'Nota_1sem': f"{nota_1sem:.2f}",
        'Nota_2sem': f"{nota_2sem:.2f}",
        'Nivel_Riesgo': riesgo
    })

# Guardar perfiles en CSV
df_profiles = pd.DataFrame(cluster_profiles)
df_profiles.to_csv("artifacts/clustering_perfiles.csv", index=False)
print(f"\n   âœ“ Perfiles guardados: artifacts/clustering_perfiles.csv")

# ====================================================================
# 10. VISUALIZACIÃ“N DE PERFILES
# ====================================================================
print("\nðŸ“Š 10. Generando grÃ¡fico de perfiles...")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# DistribuciÃ³n de estudiantes por cluster
cluster_counts = df_analysis['Cluster'].value_counts().sort_index()
axes[0, 0].bar(cluster_counts.index, cluster_counts.values, color='steelblue', alpha=0.7)
axes[0, 0].set_xlabel('Cluster')
axes[0, 0].set_ylabel('NÃºmero de Estudiantes')
axes[0, 0].set_title('DistribuciÃ³n de Estudiantes por Cluster')
axes[0, 0].grid(alpha=0.3, axis='y')

# Tasa de deserciÃ³n por cluster
desercion_por_cluster = df_analysis.groupby('Cluster')['Desercion'].mean() * 100
colors = ['green' if x < 30 else 'orange' if x < 50 else 'red' for x in desercion_por_cluster]
axes[0, 1].bar(desercion_por_cluster.index, desercion_por_cluster.values, 
               color=colors, alpha=0.7)
axes[0, 1].axhline(y=32.1, color='black', linestyle='--', label='Promedio General (32.1%)')
axes[0, 1].set_xlabel('Cluster')
axes[0, 1].set_ylabel('Tasa de DeserciÃ³n (%)')
axes[0, 1].set_title('Tasa de DeserciÃ³n por Cluster')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3, axis='y')

# Edad promedio por cluster
edad_por_cluster = df_analysis.groupby('Cluster')['Age at enrollment'].mean()
axes[1, 0].bar(edad_por_cluster.index, edad_por_cluster.values, 
               color='coral', alpha=0.7)
axes[1, 0].set_xlabel('Cluster')
axes[1, 0].set_ylabel('Edad Promedio (aÃ±os)')
axes[1, 0].set_title('Edad Promedio por Cluster')
axes[1, 0].grid(alpha=0.3, axis='y')

# Rendimiento acadÃ©mico por cluster
clusters_labels = [f'C{i}' for i in range(k_optimo)]
x_pos = np.arange(len(clusters_labels))
width = 0.35

nota_1sem_cluster = df_analysis.groupby('Cluster')['Curricular units 1st sem (grade)'].mean()
nota_2sem_cluster = df_analysis.groupby('Cluster')['Curricular units 2nd sem (grade)'].mean()

axes[1, 1].bar(x_pos - width/2, nota_1sem_cluster.values, width, 
               label='1er Semestre', color='lightblue', alpha=0.8)
axes[1, 1].bar(x_pos + width/2, nota_2sem_cluster.values, width,
               label='2do Semestre', color='lightcoral', alpha=0.8)
axes[1, 1].set_xlabel('Cluster')
axes[1, 1].set_ylabel('Nota Promedio')
axes[1, 1].set_title('Rendimiento AcadÃ©mico por Cluster')
axes[1, 1].set_xticks(x_pos)
axes[1, 1].set_xticklabels(clusters_labels)
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig("artifacts/clustering_analisis_perfiles.png", dpi=300, bbox_inches="tight")
print("   âœ“ GrÃ¡fico guardado: artifacts/clustering_analisis_perfiles.png")
plt.show()

# ====================================================================
# 11. RESUMEN FINAL Y CONCLUSIONES
# ====================================================================
print("\n" + "="*80)
print("                    RESUMEN Y CONCLUSIONES")
print("="*80)

print(f"\nðŸ“Š ALGORITMOS APLICADOS:")
print(f"   âœ“ K-Means: {k_optimo} clusters identificados")
print(f"   âœ“ DBSCAN: {list(best_dbscan).count(-1)} outliers detectados")
print(f"   âœ“ PCA: {n_components_95} componentes para 95% varianza")

print(f"\nðŸ“ˆ MÃ‰TRICAS DE CALIDAD:")
print(f"   â€¢ Silhouette Score (K-Means): {silhouette_kmeans:.3f}")
print(f"   â€¢ Davies-Bouldin Index: {davies_bouldin_kmeans:.3f}")
print(f"   â€¢ Calinski-Harabasz Index: {calinski_harabasz_kmeans:.0f}")

print(f"\nðŸŽ¯ INSIGHTS PRINCIPALES:")
print(f"   1. Se identificaron {k_optimo} perfiles distintos de estudiantes")
print(f"   2. {list(best_dbscan).count(-1)} estudiantes con comportamiento atÃ­pico (outliers)")
print(f"   3. La segmentaciÃ³n revela diferentes niveles de riesgo de deserciÃ³n")
print(f"   4. Los clusters correlacionan con las tasas reales de deserciÃ³n")

print(f"\nðŸ’¾ ARCHIVOS GENERADOS:")
print(f"   âœ“ artifacts/pca_varianza_explicada.png")
print(f"   âœ“ artifacts/clustering_metodo_codo.png")
print(f"   âœ“ artifacts/clustering_visualizacion_2d.png")
print(f"   âœ“ artifacts/clustering_visualizacion_3d.png")
print(f"   âœ“ artifacts/clustering_analisis_perfiles.png")
print(f"   âœ“ artifacts/clustering_perfiles.csv")

print("\n" + "="*80)
print("              ANÃLISIS NO SUPERVISADO COMPLETADO âœ“")
print("="*80)
